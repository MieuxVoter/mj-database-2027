# üß© BasePipeline ‚Äî Module de base pour pipelines d‚Äôextraction depuis PDF

## üìò Pr√©sentation

`base_pipeline.py` d√©finit la classe abstraite **`BasePipeline`**, qui constitue le **socle commun** de tous les pipelines d‚Äôextraction et de construction de donn√©es du projet **Cluster17 Mining**.  

Cette classe √©tablit un **mod√®le d‚Äôorchestration g√©n√©rique**, garantissant :
- la validation des param√®tres d‚Äôentr√©e,  
- le nettoyage automatique des anciens fichiers,  
- la gestion uniforme du cycle d‚Äôextraction et de construction,  
- la journalisation d√©taill√©e des op√©rations.

Elle impl√©mente le **pattern ‚ÄúTemplate Method‚Äù**, o√π la structure du flux est fix√©e mais les √©tapes concr√®tes (`extract`, `build`) sont d√©finies par les sous-classes.

---

## ‚öôÔ∏è Objectif

`BasePipeline` fournit un cadre robuste et extensible permettant :

- d‚Äôex√©cuter un pipeline complet sans r√©p√©ter la logique d‚Äôorchestration ;
- de garantir la coh√©rence des logs et la gestion des erreurs ;
- de simplifier la cr√©ation de pipelines sp√©cifiques (ex. `Cluster17Pipeline`).

---

## üß† Structure de la classe

```python
class BasePipeline(ABC):
    def __init__(self, pdf_path: Path, poll_id: str):
        ...
    @abstractmethod
    def extract(self) -> List[Dict[str, Any]]:
        ...
    @abstractmethod
    def build(self, extracted_data) -> int:
        ...
    def run(self):
        ...
````

---

## üîÅ Cycle d‚Äôex√©cution

| √âtape | Description                                   | M√©thode correspondante      |
| ----- | --------------------------------------------- | --------------------------- |
| 1     | Validation du fichier PDF et de l‚Äôidentifiant | `_validate_inputs()`        |
| 2     | Suppression des anciens fichiers CSV/TXT      | `_cleanup_existing_files()` |
| 3     | Extraction des donn√©es brutes                 | `extract()` *(abstraite)*   |
| 4     | Construction des artefacts finaux             | `build()` *(abstraite)*     |
| 5     | Journalisation du r√©sultat global             | `run()`                     |

---

## üß© Utilisation

### 1. Cr√©er une sous-classe

```python
from pathlib import Path
from mining.base_pipeline import BasePipeline

class MyPipeline(BasePipeline):
    def extract(self):
        print("Extraction en cours...")
        return [{"df": "mock_dataframe"}]

    def build(self, extracted_data):
        print(f"Construction termin√©e ({len(extracted_data)} tables trait√©es)")
        return len(extracted_data)
```

---

### 2. Ex√©cuter le pipeline

```python
if __name__ == "__main__":
    pdf_file = Path("data/cluster17_202511.pdf")
    pipeline = MyPipeline(pdf_file, poll_id="cluster17_202511")
    pipeline.run()
```

**Sortie attendue :**

```
üßπ Nettoyage des anciens fichiers avant traitement...
üîç  D√©tection et extraction des pages de donn√©es...
üì¶  Extraction et construction des CSV...
‚úÖ  1 fichier(s) CSV g√©n√©r√©(s)
```

---

## üßæ D√©tails des m√©thodes

### `__init__(self, pdf_path, poll_id)`

Initialise le pipeline et valide les entr√©es :

* `pdf_path` : chemin vers le fichier source (PDF, API, etc.)
* `poll_id` : identifiant du sondage (ex. `"cluster17_202511"`)

---

### `_validate_inputs()`

V√©rifie :

* que `pdf_path` est un `Path` existant,
* que `poll_id` est une cha√Æne valide.
  L√®ve `TypeError` ou `FileNotFoundError` en cas d‚Äôerreur.

---

### `_cleanup_existing_files(extensions=("csv", "txt"))`

Supprime les anciens fichiers `.csv` et `.txt` dans le r√©pertoire du PDF avant un nouveau traitement.
Les fichiers inaccessibles sont ignor√©s mais journalis√©s.

---

### `extract()`

M√©thode **abstraite** √† impl√©menter dans les sous-classes.
Doit renvoyer une **liste de dictionnaires** d√©crivant les tableaux extraits, par exemple :

```python
[
  {"Page": 1, "Population": "G√©n√©rale", "df": <DataFrame>},
  {"Page": 2, "Population": "Jeunes", "df": <DataFrame>}
]
```

---

### `build(extracted_data)`

M√©thode **abstraite** charg√©e de construire les fichiers finaux (CSV, TXT, etc.).
Retourne le **nombre de fichiers cr√©√©s**.

---

### `run()`

M√©thode principale orchestrant le processus complet :

1. Nettoyage des anciens fichiers
2. Extraction des donn√©es
3. Construction des artefacts
4. Journalisation du r√©sultat

---

## üß© Exemple concret ‚Äî `Cluster17Pipeline`

Impl√©mentation pratique dans `mining_CLUSTER17/orchestrator.py` :

```python
class Cluster17Pipeline(BasePipeline):
    def extract(self):
        extractor = PDFExtractor(self.pdf_path)
        return extractor.extract_all()

    def build(self, extracted_data):
        builder = CSVBuilder(self.pdf_path.parent, self.poll_id)
        return builder.build_all(extracted_data)
```

---

## ü™µ Journalisation

Le module utilise `logging` pour tracer chaque √©tape :

```
INFO  [BasePipeline] üßπ Nettoyage des anciens fichiers avant traitement...
INFO  [BasePipeline] üì¶  Extraction et construction des CSV...
ERROR [BasePipeline] Erreur inattendue dans le pipeline : <message>
```

---

## üß± Points techniques cl√©s

| √âl√©ment           | Description                                    |
| ----------------- | ---------------------------------------------- |
| **Pattern**       | Template Method Pattern                        |
| **Type**          | Classe abstraite (`ABC`)                       |
| **Objectif**      | Standardiser l‚Äôex√©cution des pipelines         |
| **Validation**    | V√©rification stricte des entr√©es               |
| **Extensibilit√©** | Compatible avec tout pipeline (PDF, API, etc.) |
| **Logs**          | Gestion compl√®te via le module `logging`       |

---
