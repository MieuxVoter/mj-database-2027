import pathlib
import logging
import re
from typing import List
import pdfplumber
import pandas as pd
from tabulate import tabulate
from pdfminer.high_level import extract_pages
from pdfminer.layout import LTTextContainer
from core.settings.logger import setup_logging
from core.helpers import normalize
from core.population import Population

setup_logging()
logger = logging.getLogger("app")


class Cluster17PDFExtractor:

    COLUMN_HEADER_PATTERNS = [
        r"vous\s+la\s+soutenez",
        r"vous\s+l['‚Äô]appreciez",
        r"vous\s+ne\s+l['‚Äô]appreciez\s*pas",
        r"vous\s+n['‚Äô]avez\s+pas\s+d['‚Äô]avis\s+sur\s+elle",
        r"vous\s+ne\s+la\s+connaissez\s+pas",
    ]

    min_table_rows: int = 3
    gap_multiplier: float = 1.8
    min_gap: float = 4.0

    def __init__(self, file: pathlib.Path, population: Population | None = None) -> None:

        self.file = file
        self.population = population

    def _is_page_relevant(self, page_layout) -> bool:
        """
        Analysez une page PDF pour d√©terminer si elle contient un tableau correspondant
        √† une sondage du Cluster 17.

        Il repose sur la d√©tection combin√©e de plusieurs crit√®res :
        - Pr√©sence du titre attendu dans le texte normalis√©.
        - Densit√© totale de lignes suffisante (indicative de tableaux).
        - Abondance de petits blocs de texte (cellules ou lignes courtes).
        - Densit√© num√©rique √©lev√©e (valeurs en pourcentage ou num√©riques).
        - Existence d'en-t√™tes attendus dans des colonnes connues.

        Args:
            page_layout: Objet it√©rable provenant de `pdfminer`
                qui contient les √©l√©ments de texte (`LTTextContainer`)
                et leur disposition sur la page.

        Returns:
            bool: `True` si la page pr√©sente les caract√©ristiques typiques
                d'un tableau de sondage Cluster 17, `False` dans le cas contraire.
        """

        page_text = ""
        text_blocks = []

        for element in page_layout:
            if isinstance(element, LTTextContainer):
                text = element.get_text().strip()

                if text:
                    page_text += text + "\n"
                    lines = [l.strip() for l in text.split("\n") if l.strip()]
                    text_blocks.append({"text": text, "line_count": len(lines)})

        normalized_text = normalize(page_text)

        #  D√©tectant le titre
        has_title = "barometre des personnalites" in normalized_text

        # Densit√© totale des lignes
        total_lines = sum(b["line_count"] for b in text_blocks)

        # Blocs (petites tables)
        small_blocks = [b for b in text_blocks if 1 <= b["line_count"] <= 4]

        # Densit√© num√©rique (% ou nombre)
        num_blocks = sum(1 for b in text_blocks if "%" in b["text"] or any(ch.isdigit() for ch in b["text"]))

        has_numeric_density = num_blocks >= 5

        # R√®gles combin√©es pour tables
        has_table_structure = (
            total_lines >= 20 or len(small_blocks) >= 25  # il y a beaucoup de lignes  # beaucoup de petits blocs
        )

        has_expected_columns = sum(bool(re.search(p, normalized_text)) for p in self.COLUMN_HEADER_PATTERNS) >= 2

        return has_title and has_table_structure and has_numeric_density and has_expected_columns
    




    def extract_data(self, start_page: int = 1) -> List:

        logger.info("")
        logger.info("üîç D√©tection des pages de donn√©es... ")

        pages = list(extract_pages(str(self.file)))
        total_pages = len(pages)

        # D√©tection des pages pertinentes contenant des sondages
        data_pages = []
        for page_num in range(start_page, total_pages + 1):
            page_layout = pages[page_num - 1]

            if self._is_page_relevant(page_layout):
                data_pages.append(page_num)

        logger.info(f"üìä {len(data_pages)} page(s) de donn√©es d√©tect√©e(s) :")
        logger.info("")

        val = 38
        self._get_tables_and_captions(val)
        self.buscar_captions_refinado(val)
        self.buscar_captions_inteligente(val)



        return []
    

    def _get_tables_and_captions(self, page_number: int):

        with pdfplumber.open(self.file) as pdf:
            total_pages = len(pdf.pages)
            if page_number < 1 or page_number > len(pdf.pages):
                logging.error(f"Num√©ro de page invalide: {page_number}. "
                                f"Le PDF ne comporte que {total_pages} pages.")
                raise ValueError(f"Le PDF ne comporte que {total_pages} pages.")
            
            page = pdf.pages[page_number - 1]
           
            # D√©tecter les tables (objets Table)
            table_objects = page.find_tables()

            logger.debug(f"Page : {page_number} ‚Äî {len(table_objects)} table(s) d√©tect√©e(s)")
            for i, t in enumerate(table_objects, start=1):
                x0, y0, x1, y1 = t.bbox
                logger.debug(f"Table {i}: bbox = ({x0:.1f}, {y0:.1f}, {x1:.1f}, {y1:.1f})")
            
            # Extraire les tables
            logger.debug(f"")
            for i, t in enumerate(table_objects, start=1):
                table_data = t.extract()  

                # cr√©ation pandas dataframe
                df = pd.DataFrame(table_data)
                # Nettoyage du DataFrame
                df = df.dropna(how="all").reset_index(drop=True)
                df.columns = df.iloc[0] if not df.empty else None
                df = df[1:] if len(df) > 1 else df    

                logger.debug(f"Table {i}")
                logger.debug("Imprimer uniquement le .head() du dataframe\n" + tabulate(df.head(), headers='keys', tablefmt='psql'))



    def buscar_captions_refinado(self, page_number, margen=100):
        """
        Busca captions justo encima de cada tabla, evitando incluir t√≠tulos de p√°gina.
        """
        resultados = []
        margen_superior=120

        with pdfplumber.open(self.file) as pdf:
            page = pdf.pages[page_number - 1]

            tables = sorted(page.find_tables(), key=lambda t: t.bbox[1])  # de arriba a abajo
            words = page.extract_words(use_text_flow=True)

            for i, t in enumerate(tables, start=1):
                x0, y_top, x1, y_bottom = t.bbox

                # l√≠mite superior: borde inferior de la tabla anterior
                y_limite_inferior = tables[i-2].bbox[3] if i > 1 else 0

                # 1Ô∏èbuscar solo entre el borde superior y la tabla anterior
                encima = [
                    w for w in words
                    if y_limite_inferior < w["bottom"] < y_top
                    and y_top - w["bottom"] < margen_superior
                    and x0 - 20 < w["x0"] < x1 + 20
                ]

                #  agrupar por l√≠nea y ordenar
                lineas = {}
                for w in encima:
                    y_line = round(w["top"], -1)
                    lineas.setdefault(y_line, []).append(w["text"])

                sorted_lines = sorted(lineas.items(), key=lambda kv: kv[0])
                ultimas_lineas = [" ".join(v) for _, v in sorted_lines[-2:]]
                caption = " ".join(ultimas_lineas).strip()

                #  limpiar t√≠tulo global y restos
                caption = re.sub(r"BAROM√àTRE DES PERSONNALIT√âS.*", "", caption, flags=re.I)
                caption = re.sub(r"^\d+\s+\S+", "", caption).strip()  # elimina si empieza con n√∫mero
                caption = re.sub(r"\s{2,}", " ", caption)

                resultados.append({
                    "tabla_id": i,
                    "bbox": t.bbox,
                    "caption": caption
                })

                print(f"Tabla {i}: '{caption}'")

        return resultados
                


    def buscar_captions_inteligente(self, page_number, margen_vertical=200, margen_horizontal=150):
        """
        Busca captions justo encima de cada tabla, con heur√≠sticas robustas.
        - Ampl√≠a m√°rgenes verticales y horizontales.
        - Usa patrones de texto t√≠picos ("√âlecteurs", "Concernant").
        """
        resultados = []

        with pdfplumber.open(self.file) as pdf:
            page = pdf.pages[page_number - 1]
            tables = sorted(page.find_tables(), key=lambda t: t.bbox[1])  # de arriba a abajo
            words = page.extract_words(use_text_flow=True)
            full_text = page.extract_text() or ""

            for i, t in enumerate(tables, start=1):
                x0, y_top, x1, y_bottom = t.bbox
                y_limite_inferior = tables[i-2].bbox[3] if i > 1 else 0

                # 1Ô∏è‚É£ Buscar texto en el margen ampliado
                encima = [
                    w for w in words
                    if y_limite_inferior < w["bottom"] < y_top
                    and y_top - w["bottom"] < margen_vertical
                    and (x0 - margen_horizontal) < w["x0"] < (x1 + margen_horizontal)
                ]

                # 2Ô∏è Agrupar l√≠neas
                lineas = {}
                for w in encima:
                    y_line = round(w["top"], -1)
                    lineas.setdefault(y_line, []).append(w["text"])

                sorted_lines = sorted(lineas.items(), key=lambda kv: kv[0])
                ultimas_lineas = [" ".join(v) for _, v in sorted_lines[-3:]]
                caption = " ".join(ultimas_lineas).strip()

                # 3Ô∏è Limpieza de ruido
                caption = re.sub(r"BAROM√àTRE DES PERSONNALIT√âS.*", "", caption, flags=re.I)
                caption = re.sub(r"^\d+\s+\S+", "", caption).strip()
                caption = re.sub(r"\s{2,}", " ", caption)

                # 4Ô∏è Heur√≠stica de rescate (buscar directamente texto tipo '√âlecteurs ‚Ä¶')
                if not caption or not re.search(r"√âlecteurs|Concernant", caption, flags=re.I):
                    regex_caption = re.search(r"(√âlecteurs[^\\n]+|Concernant[^\\n]+)", full_text, re.I)
                    caption = regex_caption.group(1).strip() if regex_caption else caption

                resultados.append({
                    "tabla_id": i,
                    "bbox": t.bbox,
                    "caption": caption
                })

                print(f" Tabla {i}: '{caption}'")

        return resultados