import logging
from abc import ABC, abstractmethod
from pathlib import Path
from typing import List, Dict, Any


class BasePipeline(ABC):
    """
    Classe de base abstraite pour les pipelines d'extraction et de construction
    de donn√©es (Cluster17, etc.).

    Elle fournit une structure commune et des validations initiales.
    """

    REQUIRED_METADATA_FIELDS = {"poll_id", "pdf_url"}

    def __init__(self, pdf_path: Path, poll_type: str):
        """
        Initialise le processus du pipeline.

        Args:
            file : Path
                Chemin complet vers le fichier PDF √† analyser.
            poll_type : str
                Identifiant du sondage (ex. "pt4").
        """

        self.pdf_path: Path = pdf_path
        self.poll_type: str = poll_type
        self.logger = logging.getLogger(self.__class__.__name__)
        self._validate_inputs()

    def _validate_inputs(self) -> None:
        """
        Valide les param√®tres d'entr√©e.
        """
        if not isinstance(self.pdf_path, Path):
            self.logger.error("Le param√®tre 'pdf_path' doit √™tre une instance de pathlib.Path.")
            raise TypeError("Le param√®tre 'pdf_path' doit √™tre une instance de pathlib.Path.")
        if not self.pdf_path.exists():
            self.logger.error(f"Le fichier sp√©cifi√© est introuvable : {self.pdf_path}")
            raise FileNotFoundError(f"Le fichier sp√©cifi√© est introuvable : {self.pdf_path}")
        if not isinstance(self.poll_type, str):
            self.logger.error("Le param√®tre 'poll_type' doit √™tre une cha√Æne de caract√®res.")
            raise TypeError("Le param√®tre 'pollpoll_type_id' doit √™tre une cha√Æne de caract√®res.")

    @abstractmethod
    def extract(self) -> tuple[Dict[str, Any], List[Dict[str, Any]]]:
        """Extraire les donn√©es de la source (PDF)"""
        pass

    @abstractmethod
    def build(self, survey_metadata, surveys) -> int:
        """Construisez les artefacts (CSV, TXT, etc.)"""
        pass

    def _validate_metadata(self) -> None:
        """
        Valide l'existence et la structure minimale du fichier metadata.txt.
        """
        metadata_file = Path(self.pdf_path.parent) / "metadata.txt"
        if not metadata_file.is_file():
            raise FileNotFoundError(f"<< metadata.txt >> requis mais absent : {metadata_file}")
        self.logger.info("‚úÖ  << metadata.txt >> d√©tect√©")

        metadata: dict[str, str] = {}
        for line_number, raw_line in enumerate(metadata_file.read_text(encoding="utf-8").splitlines(), start=1):
            line = raw_line.strip()

            # ignorer lignes vides et commentaires
            if not line or line.startswith("#"):
                continue

            if ":" not in line:
                raise ValueError(f"Structure invalide dans metadata.txt " f"(ligne {line_number}) : '{raw_line}'")

            key, value = line.split(":", 1)
            metadata[key.strip()] = value.strip()

        missing_fields = self.REQUIRED_METADATA_FIELDS - metadata.keys()
        if missing_fields:
            raise ValueError(f"Champs obligatoires manquants dans metadata.txt : {sorted(missing_fields)}")

        self.logger.info("üìÑ  Structure de << metadata.txt >> valid√©e")

    def _cleanup_existing_files(self, extensions=("csv", "txt")) -> None:
        """
        Supprime les anciens fichiers avant le traitement si n√©cessaire.
        """
        try:
            base_path = self.pdf_path.parent
            files_to_delete = []

            # Rechercher tous les fichiers correspondants
            for ext in extensions:
                for f in base_path.rglob(f"*.{ext}"):
                    if f.name == "metadata.txt":
                        continue
                    files_to_delete.append(f)

            if not files_to_delete:
                self.logger.info(f"Aucun fichier .csv/.txt trouv√© √† supprimer dans : {base_path}")
                return

            for f in files_to_delete:
                try:
                    f.unlink()
                except Exception as e:
                    self.logger.error(f"Impossible de supprimer le fichier : {f} ({e})")

            self.logger.info(f"{len(files_to_delete)} ancien(s) fichier(s) supprim√©(s) dans : {base_path}")

        except Exception as e:
            self.logger.error(f"Erreur inattendue lors du nettoyage des fichiers : {e}")

    def run(self):
        """
        Ex√©cute le pipeline complet.
        """
        try:
            self.logger.info("üìÑ  Validation du fichier << metadata.txt >>...")
            self.logger.info("=" * 70)
            self._validate_metadata()
            self.logger.info("")

            self.logger.info("üßπ Nettoyage des anciens fichiers avant traitement...")
            self.logger.info("=" * 70)
            self._cleanup_existing_files()
            self.logger.info("")

            self.logger.info("üîç  D√©tection et extraction des pages de donn√©es... ")
            self.logger.info("=" * 70)
            survey_metadata, surveys = self.extract()
            self.logger.info("")

            self.logger.info("üì¶  Extraction et construction des CSV...")
            self.logger.info("=" * 70)
            nb_csv_created = self.build(survey_metadata, surveys)
            self.logger.info("")

            self.logger.info("=" * 70)
            self.logger.info(f"‚úÖ  {nb_csv_created} fichier(s) CSV g√©n√©r√©(s)")
            self.logger.info("")

        except FileNotFoundError as e:
            self.logger.error(f"Erreur de configuration : {e}")
            raise

        except Exception as e:
            self.logger.error(f"Erreur inattendue dans le pipeline : {e}")
            raise
